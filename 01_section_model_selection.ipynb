{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Section:** Model Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jbcabral/miniconda2/envs/howfar/lib/python3.7/site-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.metrics.ranking module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.metrics. Anything that cannot be imported from sklearn.metrics is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import itertools as it\n",
    "import warnings\n",
    "import time\n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib import cm\n",
    "import seaborn as sns\n",
    "\n",
    "import joblib\n",
    "\n",
    "import pathlib\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.exceptions import DataConversionWarning\n",
    "\n",
    "from sklearn import metrics\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "import tqdm\n",
    "\n",
    "from libs.container import Container\n",
    "from libs.nearest import nearest\n",
    "from libs.experiment import WithAnotherExperiment, roc, metrics\n",
    "from libs.precstar import  prec_star\n",
    "\n",
    "warnings.simplefilter(\"ignore\", category=DataConversionWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = pathlib.Path(os.path.abspath(os.path.dirname(\"\")))\n",
    "\n",
    "DATA_PATH = PATH / \"_data\" / \"s5k_scaled.pkl.bz2\"\n",
    "\n",
    "COLUMNS_NO_FEATURES = ['id', 'tile', 'cnt', 'ra_k', 'dec_k', 'vs_type', 'vs_catalog', 'cls'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = pd.read_pickle(DATA_PATH)\n",
    "\n",
    "# the features\n",
    "X_columns = [c for c in sample.columns if c not in COLUMNS_NO_FEATURES]\n",
    "y_column = \"cls\"\n",
    "\n",
    "sample[X_columns] =  sample[X_columns].astype(np.float32)\n",
    "\n",
    "data = Container({k: v for k, v in sample.groupby(\"tile\") if k in [\"b234\", \"b360\", \"b278\", \"b261\"]})\n",
    "\n",
    "del sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_func(y, y_prob, **kwargs):\n",
    "    prec, rec, thr = metrics.precision_recall_curve(\n",
    "            y, y_prob, sample_weight=None)\n",
    "    idx = nearest(array=rec, value=.9)\n",
    "    return prec[idx]\n",
    "\n",
    "\n",
    "def grid_search(data, estimator, param_grid):\n",
    "    print(f\"Running {type(estimator)}\")\n",
    "    clf = GridSearchCV(\n",
    "        estimator, \n",
    "        param_grid, \n",
    "        cv=5, scoring=metrics.make_scorer(score_func, needs_proba=True), n_jobs=-1)\n",
    "\n",
    "    X, y = data[X_columns].values, data.cls.values\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    print(\"Best parameters set found on development set:\")\n",
    "    print()\n",
    "    print(clf.best_params_)\n",
    "\n",
    "    print()\n",
    "    print(\"Grid scores on development set:\")\n",
    "    print()\n",
    "    means = clf.cv_results_['mean_test_score']\n",
    "    stds = clf.cv_results_['std_test_score']\n",
    "    for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
    "        print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "              % (mean, std * 2, params))\n",
    "    print()\n",
    "\n",
    "    print(\"Detailed classification report:\")\n",
    "    print()\n",
    "    print(\"The model is trained on the full development set.\")\n",
    "    print(\"The scores are computed on the full evaluation set.\")\n",
    "    print()\n",
    "    y_true, y_pred = y_test, clf.predict(X_test)\n",
    "    print(classification_report(y_true, y_pred))\n",
    "    print()\n",
    "\n",
    "    return clf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM-Linear "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "[{'kernel': ['linear'], 'C': [1, 10, 100, 1000]}] -> {'C': 1000, 'kernel': 'linear'}\n",
    "[{'kernel': ['linear'], 'C': [500, 1000, 5000]}]  -> {'C': 5000, 'kernel': 'linear'}\n",
    "[{'kernel': ['linear'], 'C': [2500, 5000, 7500]}] -> {'C': 5000, 'kernel': 'linear'}\n",
    "[{'kernel': ['linear'], 'C': [4000, 4500, 5000]}] -> {'C': 4000, 'kernel': 'linear'}\n",
    "[{'kernel': ['linear'], 'C': [3000, 3500, 4000]}] -> {'C': 4000, 'kernel': 'linear'}\n",
    "[{'kernel': ['linear'], 'C': [3900, 4000, 4100]}] -> {'C': 3900, 'kernel': 'linear'}\n",
    "[{'kernel': ['linear'], 'C': [3700, 3800, 3900]}] -> {'C': 3700, 'kernel': 'linear'}\n",
    "[{'kernel': ['linear'], 'C': [3700, 3600, 3650]}] -> {'C': 3700, 'kernel': 'linear'}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3 µs, sys: 0 ns, total: 3 µs\n",
      "Wall time: 9.78 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# start = time.time()\n",
    "# svc_linear1 = grid_search(\n",
    "#     data=data.b278, \n",
    "#     estimator=SVC(probability=True),\n",
    "#     param_grid=[{'kernel': ['linear'], 'C': [3000, 3500, 4000], \"probability\": True}])\n",
    "# end = time.time() - start"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM-RBF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.e-09, 1.e-08, 1.e-07, 1.e-06, 1.e-05, 1.e-04, 1.e-03, 1.e-02,\n",
       "       1.e-01, 1.e+00, 1.e+01, 1.e+02, 1.e+03])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gamma_range = np.logspace(-9, 3, 13)\n",
    "gamma_range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running <class 'sklearn.svm._classes.SVC'>\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'C': 3000, 'gamma': 0.0001, 'kernel': 'rbf', 'probability': True}\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.595 (+/-0.199) for {'C': 3000, 'gamma': 1e-09, 'kernel': 'rbf', 'probability': True}\n",
      "0.578 (+/-0.187) for {'C': 3000, 'gamma': 1e-08, 'kernel': 'rbf', 'probability': True}\n",
      "0.593 (+/-0.178) for {'C': 3000, 'gamma': 1e-07, 'kernel': 'rbf', 'probability': True}\n",
      "0.626 (+/-0.205) for {'C': 3000, 'gamma': 1e-06, 'kernel': 'rbf', 'probability': True}\n",
      "0.659 (+/-0.227) for {'C': 3000, 'gamma': 1e-05, 'kernel': 'rbf', 'probability': True}\n",
      "0.704 (+/-0.176) for {'C': 3000, 'gamma': 0.0001, 'kernel': 'rbf', 'probability': True}\n",
      "0.590 (+/-0.050) for {'C': 3000, 'gamma': 0.001, 'kernel': 'rbf', 'probability': True}\n",
      "0.631 (+/-0.232) for {'C': 3000, 'gamma': 0.01, 'kernel': 'rbf', 'probability': True}\n",
      "0.650 (+/-0.173) for {'C': 3000, 'gamma': 0.1, 'kernel': 'rbf', 'probability': True}\n",
      "0.069 (+/-0.001) for {'C': 3000, 'gamma': 1.0, 'kernel': 'rbf', 'probability': True}\n",
      "0.077 (+/-0.001) for {'C': 3000, 'gamma': 10.0, 'kernel': 'rbf', 'probability': True}\n",
      "0.077 (+/-0.001) for {'C': 3000, 'gamma': 100.0, 'kernel': 'rbf', 'probability': True}\n",
      "0.077 (+/-0.001) for {'C': 3000, 'gamma': 1000.0, 'kernel': 'rbf', 'probability': True}\n",
      "0.594 (+/-0.203) for {'C': 3500, 'gamma': 1e-09, 'kernel': 'rbf', 'probability': True}\n",
      "0.578 (+/-0.187) for {'C': 3500, 'gamma': 1e-08, 'kernel': 'rbf', 'probability': True}\n",
      "0.603 (+/-0.199) for {'C': 3500, 'gamma': 1e-07, 'kernel': 'rbf', 'probability': True}\n",
      "0.632 (+/-0.195) for {'C': 3500, 'gamma': 1e-06, 'kernel': 'rbf', 'probability': True}\n",
      "0.663 (+/-0.219) for {'C': 3500, 'gamma': 1e-05, 'kernel': 'rbf', 'probability': True}\n",
      "0.691 (+/-0.175) for {'C': 3500, 'gamma': 0.0001, 'kernel': 'rbf', 'probability': True}\n",
      "0.601 (+/-0.043) for {'C': 3500, 'gamma': 0.001, 'kernel': 'rbf', 'probability': True}\n",
      "0.631 (+/-0.232) for {'C': 3500, 'gamma': 0.01, 'kernel': 'rbf', 'probability': True}\n",
      "0.650 (+/-0.173) for {'C': 3500, 'gamma': 0.1, 'kernel': 'rbf', 'probability': True}\n",
      "0.069 (+/-0.001) for {'C': 3500, 'gamma': 1.0, 'kernel': 'rbf', 'probability': True}\n",
      "0.077 (+/-0.001) for {'C': 3500, 'gamma': 10.0, 'kernel': 'rbf', 'probability': True}\n",
      "0.077 (+/-0.001) for {'C': 3500, 'gamma': 100.0, 'kernel': 'rbf', 'probability': True}\n",
      "0.077 (+/-0.001) for {'C': 3500, 'gamma': 1000.0, 'kernel': 'rbf', 'probability': True}\n",
      "0.592 (+/-0.198) for {'C': 4000, 'gamma': 1e-09, 'kernel': 'rbf', 'probability': True}\n",
      "0.578 (+/-0.187) for {'C': 4000, 'gamma': 1e-08, 'kernel': 'rbf', 'probability': True}\n",
      "0.612 (+/-0.204) for {'C': 4000, 'gamma': 1e-07, 'kernel': 'rbf', 'probability': True}\n",
      "0.629 (+/-0.200) for {'C': 4000, 'gamma': 1e-06, 'kernel': 'rbf', 'probability': True}\n",
      "0.671 (+/-0.206) for {'C': 4000, 'gamma': 1e-05, 'kernel': 'rbf', 'probability': True}\n",
      "0.691 (+/-0.185) for {'C': 4000, 'gamma': 0.0001, 'kernel': 'rbf', 'probability': True}\n",
      "0.598 (+/-0.051) for {'C': 4000, 'gamma': 0.001, 'kernel': 'rbf', 'probability': True}\n",
      "0.631 (+/-0.232) for {'C': 4000, 'gamma': 0.01, 'kernel': 'rbf', 'probability': True}\n",
      "0.650 (+/-0.174) for {'C': 4000, 'gamma': 0.1, 'kernel': 'rbf', 'probability': True}\n",
      "0.069 (+/-0.001) for {'C': 4000, 'gamma': 1.0, 'kernel': 'rbf', 'probability': True}\n",
      "0.077 (+/-0.001) for {'C': 4000, 'gamma': 10.0, 'kernel': 'rbf', 'probability': True}\n",
      "0.077 (+/-0.001) for {'C': 4000, 'gamma': 100.0, 'kernel': 'rbf', 'probability': True}\n",
      "0.077 (+/-0.001) for {'C': 4000, 'gamma': 1000.0, 'kernel': 'rbf', 'probability': True}\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.98       986\n",
      "           1       0.92      0.77      0.84       101\n",
      "\n",
      "    accuracy                           0.97      1087\n",
      "   macro avg       0.95      0.88      0.91      1087\n",
      "weighted avg       0.97      0.97      0.97      1087\n",
      "\n",
      "\n",
      "CPU times: user 3.1 s, sys: 153 ms, total: 3.25 s\n",
      "Wall time: 2min 43s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "start = time.time()\n",
    "svc_rbf = grid_search(\n",
    "    data=data.b278, \n",
    "    estimator=SVC(),\n",
    "    param_grid=[{'kernel': ['rbf'], 'C': [3000, 3500, 4000], \"gamma\": gamma_range, \"probability\": [True]}])\n",
    "end = time.time() - start"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
       "       18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k_range = np.arange(1, 30)\n",
    "k_range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running <class 'sklearn.neighbors._classification.KNeighborsClassifier'>\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "start = time.time()\n",
    "\n",
    "knn = grid_search(\n",
    "    data=data.b278, \n",
    "    estimator=KNeighborsClassifier(),\n",
    "    param_grid=[{\n",
    "        \"weights\": ['uniform', 'distance'], \n",
    "        \"algorithm\": ['auto', 'ball_tree', 'kd_tree', 'brute'],\n",
    "        \"p\": [1, 2, 3],\n",
    "        \"n_neighbors\": k_range}])\n",
    "\n",
    "end = time.time() - start"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "start = time.time()\n",
    "\n",
    "rf = grid_search(\n",
    "    data=data.b278, \n",
    "    estimator=RandomForestClassifier(),\n",
    "    param_grid=[{\n",
    "        'max_features': ['auto', 'sqrt', \"log2\", None, 0.2, 0.5], \n",
    "        \"min_samples_split\": [2, 5, 10],\n",
    "        \"n_estimators\": [500], \n",
    "        \"criterion\": [\"entropy\"], \n",
    "        \"n_jobs\": [10]}]\n",
    ")\n",
    "\n",
    "end = time.time() - start"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the classifiers with the selected parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CLFS_CLASSES = {\n",
    "    \"RF\": RandomForestClassifier,\n",
    "    \"KNN\": KNeighborsClassifier,\n",
    "    \"SVM-Linear\": SVC,\n",
    "    \"SVM-RBF\": SVC,\n",
    "}\n",
    "\n",
    "CLFS_PARAMS = {\n",
    "    \"RF\":{\n",
    "        'criterion': 'entropy',\n",
    "         'max_features': 'log2',\n",
    "         'min_samples_split': 5,\n",
    "         'n_estimators': 500},\n",
    "    \n",
    "    \"KNN\": {\n",
    "        'algorithm': 'auto', \n",
    "        'n_neighbors': 29, \n",
    "        'p': 1, \n",
    "        'weights': \n",
    "        'distance'},\n",
    "    \n",
    "    \"SVM-Linear\": {\"probability\": True, 'C': 3700, 'kernel': 'linear'},\n",
    "    \n",
    "    \"SVM-RBF\": {\"probability\": True, 'C': 3500, 'gamma': 0.001, 'kernel': 'rbf'}\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_clf(tile_name, clf_name, df, X_columns):    \n",
    "    X_train = df[X_columns].values\n",
    "    y_train = df.cls.values\n",
    "    \n",
    "    clf_class = CLFS_CLASSES[clf_name]\n",
    "    clf_params = CLFS_PARAMS[clf_name]\n",
    "    \n",
    "    clf = clf_class(**clf_params)\n",
    "    clf.fit(X_train, y_train)\n",
    "    return tile_name, clf\n",
    "\n",
    "\n",
    "def get_clfs(clf_name, data, X_columns):\n",
    "    with joblib.Parallel(n_jobs=-1) as jobs:\n",
    "        clfs = jobs(\n",
    "            joblib.delayed(make_clf)(tile_name, clf_name, df, X_columns)\n",
    "            for tile_name, df in sorted(tqdm.tqdm(data.items())))\n",
    "    return Container(clfs)\n",
    "\n",
    "\n",
    "def get_combs(clf_name, data, X_columns):\n",
    "    combs = []\n",
    "    clfs = get_clfs(clf_name, data, X_columns)\n",
    "    for train_name, clf in clfs.items():\n",
    "        for test_name in clfs.keys():\n",
    "            if train_name != test_name:\n",
    "                test_sample = data[test_name]\n",
    "                comb = Container({\n",
    "                    \"idx\": len(combs), \n",
    "                    \"train_name\": train_name, \"clf\": clf,  \n",
    "                    \"test_name\": test_name, \"test_sample\": test_sample, \"X_columns\": X_columns,\n",
    "                    \"clf_name\": clf_name, \"y_column\": y_column})\n",
    "                combs.append(comb)\n",
    "    return combs\n",
    "\n",
    "def execute_clf(idx, train_name, clf_name, clf, test_name, test_sample, X_columns, y_column):\n",
    "    \n",
    "    X_test = test_sample[X_columns].values\n",
    "    y_test = test_sample[y_column].values\n",
    "    \n",
    "    predictions = clf.predict(X_test)\n",
    "    probabilities = clf.predict_proba(X_test)\n",
    "    \n",
    "    fpr, tpr, thresholds = metrics.roc_curve(\n",
    "        y_test, 1.-probabilities[:,0], pos_label=1)\n",
    "\n",
    "    prec_rec_curve = metrics.precision_recall_curve(\n",
    "        y_test, 1.- probabilities[:,0], pos_label=1)\n",
    "\n",
    "    roc_auc = metrics.auc(fpr, tpr)\n",
    "    \n",
    "    result = Container({\n",
    "        \"idx\": idx,\n",
    "        \"clf_name\": clf_name,\n",
    "        \"train_name\": train_name,\n",
    "        \"test_name\": test_name,\n",
    "        'fpr': fpr,\n",
    "        'tpr': tpr,\n",
    "        'thresh': thresholds,\n",
    "        'roc_auc': roc_auc,\n",
    "        'prec_rec_curve': prec_rec_curve,\n",
    "        'real_cls': y_test,\n",
    "        'predictions': predictions,\n",
    "        'probabilities': probabilities,\n",
    "        'confusion_matrix': metrics.confusion_matrix(y_test, predictions)})    \n",
    "    return result\n",
    "\n",
    "def train_and_run(clf_name, data, X_columns):\n",
    "    combs = get_combs(clf_name, data, X_columns)\n",
    "    print(\"Combinaciones: {}\".format(len(combs)))    \n",
    "    with joblib.Parallel(n_jobs=-1) as jobs:\n",
    "        results = jobs(\n",
    "            joblib.delayed(execute_clf)(**comb) for comb in tqdm.tqdm(combs))\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "rf_test = train_and_run(\"RF\", data, X_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "knn_test = train_and_run(\"KNN\", data, X_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "svml_test = train_and_run(\"SVM-Linear\", data, X_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "svmr_test = train_and_run(\"SVM-RBF\", data, X_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump({\n",
    "    \"rf_test\": rf_test,\n",
    "    \"knn_test\": knn_test,\n",
    "    \"svml_test\": svml_test,\n",
    "    \"svmr_test\": svmr_test,}, \"_cache/model_select.pkl.bz2\", compress=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
